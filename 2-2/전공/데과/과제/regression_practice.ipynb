{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MtZPyR8oubd",
        "outputId": "cca534d0-6908-4ba1-e039-016038037d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "y = tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.],\n",
            "        [7., 8., 9.]])\n",
            "Size: torch.Size([3, 3])\n",
            "Shape: torch.Size([3, 3])\n",
            "차원(랭크): 2\n",
            "x0.shape: torch.Size([1, 3, 3])\n",
            "x1.shape: torch.Size([3, 1, 3])\n",
            "x2.shape: torch.Size([3, 3, 1])\n",
            "x0 = tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]])\n",
            "x1 = tensor([[[1, 2, 3]],\n",
            "\n",
            "        [[4, 5, 6]],\n",
            "\n",
            "        [[7, 8, 9]]])\n",
            "x2 = tensor([[[1],\n",
            "         [2],\n",
            "         [3]],\n",
            "\n",
            "        [[4],\n",
            "         [5],\n",
            "         [6]],\n",
            "\n",
            "        [[7],\n",
            "         [8],\n",
            "         [9]]])\n",
            "x3 = tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "x3.shape = torch.Size([3, 3])\n",
            "x4 = tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "x5 = tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]])\n"
          ]
        }
      ],
      "source": [
        "#텐서\n",
        "import torch\n",
        "x = torch.tensor([[1,2,3], [4,5,6], [7,8,9]])\n",
        "y = torch.FloatTensor([[1,2,3], [4,5,6], [7,8,9]])\n",
        "print(\"x =\", x)\n",
        "print(\"y =\", y)\n",
        "\n",
        "print(\"Size:\", x.size())\n",
        "print(\"Shape:\", x.shape)\n",
        "print(\"차원(랭크):\", x.ndimension())\n",
        "\n",
        "x0 = torch.unsqueeze(x, 0)\n",
        "x1 = torch.unsqueeze(x, 1)\n",
        "x2 = torch.unsqueeze(x, 2)\n",
        "print(\"x0.shape:\", x0.shape)\n",
        "print(\"x1.shape:\", x1.shape)\n",
        "print(\"x2.shape:\", x2.shape)\n",
        "print(\"x0 =\", x0)\n",
        "print(\"x1 =\", x1)\n",
        "print(\"x2 =\", x2)\n",
        "\n",
        "x3 = torch.squeeze(torch.squeeze(x0))\n",
        "print(\"x3 =\", x3)\n",
        "print(\"x3.shape =\", x3.shape)\n",
        "\n",
        "x4 = x.view(9)\n",
        "x5 = x.view(1,3,3)\n",
        "print(\"x4 =\", x4)\n",
        "print(\"x5 =\", x5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#행렬연산\n",
        "x = torch.FloatTensor([[1,2], [3,4], [5,6]])\n",
        "w = torch.randn(1,2, dtype=torch.float)\n",
        "b = torch.randn(3,1, dtype=torch.float)\n",
        "result = torch.mm(x, torch.t(w)) + b\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBgZhc4_pdtu",
        "outputId": "a9114ea0-a498-4919-c90c-1a719f762d05"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.4524],\n",
            "        [-5.5347],\n",
            "        [-6.2544]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#autograd\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "a = w*3\n",
        "l = a**2\n",
        "l.backward()\n",
        "print('l을 w로 미분한 값은', w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5twMAuzpp89",
        "outputId": "d8bb018c-2075-45e6-d7b4-126c6ef44852"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l을 w로 미분한 값은 tensor(18.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rinear regression\n",
        "import torch\n",
        "x_train = torch.FloatTensor([[1,2], [3,2], [3,7], [1,1], [1,0]])\n",
        "y_train = torch.FloatTensor([[4], [8], [23], [1], [-2]])\n",
        "W = torch.rand(2,1)\n",
        "b = torch.rand(1,1)\n",
        "lr = 0.01\n",
        "\n",
        "for epoch in range(3001):\n",
        "  W.requires_grad_(True)\n",
        "  b.requires_grad_(True)\n",
        "\n",
        "  hypothesis = torch.mm(x_train, W) + b\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "  cost.backward()\n",
        "  with torch.no_grad() as grd:\n",
        "    W = W - lr * W.grad\n",
        "    b = b - lr * b.grad\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print( 'epoch: {}, cost: {:.6f}, W: {}, b: {}'.format(epoch,\n",
        "    cost.item(), W.squeeze(), b))\n",
        "  x_test = torch.FloatTensor([[5,10]])\n",
        "\n",
        "test_result = torch.mm(x_test, W) + b\n",
        "print(test_result.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOyR4umTqD9_",
        "outputId": "bf270afc-973d-4867-d696-f4f01edf2c7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 37.555271, W: tensor([1.0299, 1.3277]), b: tensor([[0.9726]])\n",
            "epoch: 100, cost: 1.893972, W: tensor([0.5075, 3.1565]), b: tensor([[-1.0717]])\n",
            "epoch: 200, cost: 0.924439, W: tensor([0.8046, 3.2035]), b: tensor([[-1.9875]])\n",
            "epoch: 300, cost: 0.474458, W: tensor([1.1288, 3.1562]), b: tensor([[-2.5671]])\n",
            "epoch: 400, cost: 0.243825, W: tensor([1.3739, 3.1132]), b: tensor([[-2.9739]])\n",
            "epoch: 500, cost: 0.125306, W: tensor([1.5510, 3.0813]), b: tensor([[-3.2645]])\n",
            "epoch: 600, cost: 0.064397, W: tensor([1.6781, 3.0583]), b: tensor([[-3.4728]])\n",
            "epoch: 700, cost: 0.033095, W: tensor([1.7692, 3.0418]), b: tensor([[-3.6220]])\n",
            "epoch: 800, cost: 0.017008, W: tensor([1.8345, 3.0299]), b: tensor([[-3.7290]])\n",
            "epoch: 900, cost: 0.008741, W: tensor([1.8814, 3.0215]), b: tensor([[-3.8058]])\n",
            "epoch: 1000, cost: 0.004492, W: tensor([1.9150, 3.0154]), b: tensor([[-3.8607]])\n",
            "epoch: 1100, cost: 0.002309, W: tensor([1.9390, 3.0110]), b: tensor([[-3.9002]])\n",
            "epoch: 1200, cost: 0.001186, W: tensor([1.9563, 3.0079]), b: tensor([[-3.9284]])\n",
            "epoch: 1300, cost: 0.000610, W: tensor([1.9687, 3.0057]), b: tensor([[-3.9487]])\n",
            "epoch: 1400, cost: 0.000313, W: tensor([1.9775, 3.0041]), b: tensor([[-3.9632]])\n",
            "epoch: 1500, cost: 0.000161, W: tensor([1.9839, 3.0029]), b: tensor([[-3.9736]])\n",
            "epoch: 1600, cost: 0.000083, W: tensor([1.9885, 3.0021]), b: tensor([[-3.9811]])\n",
            "epoch: 1700, cost: 0.000043, W: tensor([1.9917, 3.0015]), b: tensor([[-3.9864]])\n",
            "epoch: 1800, cost: 0.000022, W: tensor([1.9941, 3.0011]), b: tensor([[-3.9903]])\n",
            "epoch: 1900, cost: 0.000011, W: tensor([1.9957, 3.0008]), b: tensor([[-3.9930]])\n",
            "epoch: 2000, cost: 0.000006, W: tensor([1.9970, 3.0006]), b: tensor([[-3.9950]])\n",
            "epoch: 2100, cost: 0.000003, W: tensor([1.9978, 3.0004]), b: tensor([[-3.9964]])\n",
            "epoch: 2200, cost: 0.000002, W: tensor([1.9984, 3.0003]), b: tensor([[-3.9974]])\n",
            "epoch: 2300, cost: 0.000001, W: tensor([1.9989, 3.0002]), b: tensor([[-3.9982]])\n",
            "epoch: 2400, cost: 0.000000, W: tensor([1.9992, 3.0001]), b: tensor([[-3.9987]])\n",
            "epoch: 2500, cost: 0.000000, W: tensor([1.9994, 3.0001]), b: tensor([[-3.9991]])\n",
            "epoch: 2600, cost: 0.000000, W: tensor([1.9996, 3.0001]), b: tensor([[-3.9993]])\n",
            "epoch: 2700, cost: 0.000000, W: tensor([1.9997, 3.0001]), b: tensor([[-3.9995]])\n",
            "epoch: 2800, cost: 0.000000, W: tensor([1.9998, 3.0000]), b: tensor([[-3.9996]])\n",
            "epoch: 2900, cost: 0.000000, W: tensor([1.9998, 3.0000]), b: tensor([[-3.9997]])\n",
            "epoch: 3000, cost: 0.000000, W: tensor([1.9999, 3.0000]), b: tensor([[-3.9998]])\n",
            "35.99983215332031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "x = [[1,2], [3,2], [3,7], [1,1], [1,0]]\n",
        "y = [[4], [8], [23], [1], [-2]]\n",
        "lr = LinearRegression() # 모델 생성\n",
        "lr.fit(x, y) # 학습 (피팅)\n",
        "print(lr.coef_, lr.intercept_)\n",
        "\n",
        "print(lr.predict([[5,10]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Afc6V5q-nz",
        "outputId": "a08bb175-a80a-4157-8622-b9c5be148d8e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2. 3.]] [-4.]\n",
            "[[36.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic regression\n",
        "import torch\n",
        "x_train = torch.FloatTensor([[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]])\n",
        "y_train = torch.FloatTensor([[1],[1],[1],[0],[0],[0],[0],[1],[0],[1],[1],[1]])\n",
        "W = torch.zeros(1,1)\n",
        "b = torch.zeros(1,1)\n",
        "lr = 1.0\n",
        "\n",
        "for epoch in range(3001):\n",
        "  W.requires_grad_(True)\n",
        "  b.requires_grad_(True)\n",
        "  hypothesis = torch.sigmoid(torch.mm(x_train, W) + b)\n",
        "  cost = torch.mean(-y_train * torch.log(hypothesis)\n",
        "  -(1 - y_train) * torch.log(1 - hypothesis))\n",
        "  cost.backward()\n",
        "  with torch.no_grad() as grd:\n",
        "    W = W - lr * W.grad\n",
        "    b = b - lr * b.grad\n",
        "  if epoch % 100 == 0:\n",
        "    print( 'epoch: {}, cost: {:.6f}, W: {:.6f}, b: {:.6f}'.format(\n",
        "    epoch, cost.item(), W.squeeze(), b.squeeze()))\n",
        "\n",
        "x_test = torch.FloatTensor([[4.5],[1.1]])\n",
        "test_result = torch.sigmoid(torch.mm(x_test, W) + b)\n",
        "print(torch.round(test_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9BBJDsprMjp",
        "outputId": "31315c44-d351-44a8-a1d8-40ce00a00a72"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 0.693147, W: -0.154167, b: 0.083333\n",
            "epoch: 100, cost: 0.420221, W: -1.451281, b: 4.406925\n",
            "epoch: 200, cost: 0.398721, W: -1.898433, b: 5.773750\n",
            "epoch: 300, cost: 0.390820, W: -2.174322, b: 6.609553\n",
            "epoch: 400, cost: 0.387009, W: -2.367329, b: 7.191599\n",
            "epoch: 500, cost: 0.384924, W: -2.510626, b: 7.622530\n",
            "epoch: 600, cost: 0.383699, W: -2.620779, b: 7.953164\n",
            "epoch: 700, cost: 0.382944, W: -2.707397, b: 8.212804\n",
            "epoch: 800, cost: 0.382463, W: -2.776597, b: 8.420023\n",
            "epoch: 900, cost: 0.382149, W: -2.832521, b: 8.587363\n",
            "epoch: 1000, cost: 0.381941, W: -2.878112, b: 8.723699\n",
            "epoch: 1100, cost: 0.381801, W: -2.915530, b: 8.835541\n",
            "epoch: 1200, cost: 0.381706, W: -2.946401, b: 8.927779\n",
            "epoch: 1300, cost: 0.381641, W: -2.971979, b: 9.004180\n",
            "epoch: 1400, cost: 0.381596, W: -2.993242, b: 9.067673\n",
            "epoch: 1500, cost: 0.381565, W: -3.010968, b: 9.120598\n",
            "epoch: 1600, cost: 0.381543, W: -3.025776, b: 9.164800\n",
            "epoch: 1700, cost: 0.381528, W: -3.038172, b: 9.201797\n",
            "epoch: 1800, cost: 0.381517, W: -3.048561, b: 9.232802\n",
            "epoch: 1900, cost: 0.381509, W: -3.057279, b: 9.258815\n",
            "epoch: 2000, cost: 0.381504, W: -3.064605, b: 9.280675\n",
            "epoch: 2100, cost: 0.381500, W: -3.070765, b: 9.299053\n",
            "epoch: 2200, cost: 0.381497, W: -3.075948, b: 9.314517\n",
            "epoch: 2300, cost: 0.381495, W: -3.080314, b: 9.327539\n",
            "epoch: 2400, cost: 0.381494, W: -3.083991, b: 9.338510\n",
            "epoch: 2500, cost: 0.381493, W: -3.087090, b: 9.347754\n",
            "epoch: 2600, cost: 0.381493, W: -3.089704, b: 9.355551\n",
            "epoch: 2700, cost: 0.381492, W: -3.091908, b: 9.362126\n",
            "epoch: 2800, cost: 0.381492, W: -3.093769, b: 9.367676\n",
            "epoch: 2900, cost: 0.381491, W: -3.095338, b: 9.372355\n",
            "epoch: 3000, cost: 0.381491, W: -3.096662, b: 9.376306\n",
            "tensor([[0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer\n",
        "import torch\n",
        "x_train = torch.FloatTensor([[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]])\n",
        "y_train = torch.FloatTensor([[1],[1],[1],[0],[0],[0],[0],[1],[0],[1],[1],[1]])\n",
        "W = torch.zeros(1,1)\n",
        "b = torch.zeros(1,1)\n",
        "lr = 1.0\n",
        "optimizer = torch.optim.SGD([W,b], lr=1.0)\n",
        "#optimizer = torch.optim.Adam([W,b], lr=1.0)\n",
        "#optimizer = torch.optim.Adadelta([W,b])\n",
        "#optimizer = torch.optim.Adagrad([W,b])\n",
        "#optimizer = torch.optim.RMSprop([W,b])\n",
        "\n",
        "for epoch in range(3001):\n",
        "  W.requires_grad_(True)\n",
        "  b.requires_grad_(True)\n",
        "  hypothesis = torch.sigmoid(torch.mm(x_train, W) + b)\n",
        "  cost = torch.mean(-y_train * torch.log(hypothesis)\n",
        "  -(1 - y_train) * torch.log(1 - hypothesis))\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print( 'epoch: {}, cost: {:.6f}, W: {:.6f}, b: {:.6f}'.format(\n",
        "    epoch, cost.item(), W.squeeze(), b.squeeze()))\n",
        "\n",
        "x_test = torch.FloatTensor([[4.5],[1.1]])\n",
        "test_result = torch.sigmoid(torch.mm(x_test, W) + b)\n",
        "print(torch.round(test_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnETNWo4r3by",
        "outputId": "5494a282-72fb-4024-cbcc-168977c7c10f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 0.693147, W: -0.154167, b: 0.083333\n",
            "epoch: 100, cost: 0.420221, W: -1.451281, b: 4.406925\n",
            "epoch: 200, cost: 0.398721, W: -1.898433, b: 5.773750\n",
            "epoch: 300, cost: 0.390820, W: -2.174322, b: 6.609553\n",
            "epoch: 400, cost: 0.387009, W: -2.367329, b: 7.191599\n",
            "epoch: 500, cost: 0.384924, W: -2.510626, b: 7.622530\n",
            "epoch: 600, cost: 0.383699, W: -2.620779, b: 7.953164\n",
            "epoch: 700, cost: 0.382944, W: -2.707397, b: 8.212804\n",
            "epoch: 800, cost: 0.382463, W: -2.776597, b: 8.420023\n",
            "epoch: 900, cost: 0.382149, W: -2.832521, b: 8.587363\n",
            "epoch: 1000, cost: 0.381941, W: -2.878112, b: 8.723699\n",
            "epoch: 1100, cost: 0.381801, W: -2.915530, b: 8.835541\n",
            "epoch: 1200, cost: 0.381706, W: -2.946401, b: 8.927779\n",
            "epoch: 1300, cost: 0.381641, W: -2.971979, b: 9.004180\n",
            "epoch: 1400, cost: 0.381596, W: -2.993242, b: 9.067673\n",
            "epoch: 1500, cost: 0.381565, W: -3.010968, b: 9.120598\n",
            "epoch: 1600, cost: 0.381543, W: -3.025776, b: 9.164800\n",
            "epoch: 1700, cost: 0.381528, W: -3.038172, b: 9.201797\n",
            "epoch: 1800, cost: 0.381517, W: -3.048561, b: 9.232802\n",
            "epoch: 1900, cost: 0.381509, W: -3.057279, b: 9.258815\n",
            "epoch: 2000, cost: 0.381504, W: -3.064605, b: 9.280675\n",
            "epoch: 2100, cost: 0.381500, W: -3.070765, b: 9.299053\n",
            "epoch: 2200, cost: 0.381497, W: -3.075948, b: 9.314517\n",
            "epoch: 2300, cost: 0.381495, W: -3.080314, b: 9.327539\n",
            "epoch: 2400, cost: 0.381494, W: -3.083991, b: 9.338510\n",
            "epoch: 2500, cost: 0.381493, W: -3.087090, b: 9.347754\n",
            "epoch: 2600, cost: 0.381493, W: -3.089704, b: 9.355551\n",
            "epoch: 2700, cost: 0.381492, W: -3.091908, b: 9.362126\n",
            "epoch: 2800, cost: 0.381492, W: -3.093769, b: 9.367676\n",
            "epoch: 2900, cost: 0.381491, W: -3.095338, b: 9.372355\n",
            "epoch: 3000, cost: 0.381491, W: -3.096662, b: 9.376306\n",
            "tensor([[0.],\n",
            "        [1.]], grad_fn=<RoundBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "W.requires_grad_(False)\n",
        "b.requires_grad_(False)\n",
        "plt.scatter(x_train, y_train, c=\"black\")\n",
        "X = torch.linspace(0,5,100).unsqueeze(1)\n",
        "Y = torch.sigmoid(torch.mm(X,W)+b)\n",
        "plt.plot(X, Y, c=\"#ff0000\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "el8RZ_1Msf1B",
        "outputId": "2b2a9e4a-01e4-4c36-df99-3f67327fc88e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sklearn logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "x_train = [[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]]\n",
        "y_train = [1,1,1,0,0,0,0,1,0,1,1,1] # 입력 shape이 pytorch에서와 다름에 주의!\n",
        "model = LogisticRegression(penalty=None) # penalty (or regularization)은 추후 설명\n",
        "model.fit(x_train, y_train)\n",
        "#W와 b에 해당하는 값 출력\n",
        "print(model.coef_, model.intercept_)\n",
        "# 새로운 x값이 주어질 때 y값 예측해보기\n",
        "x_test = [[4.5],[1.1]]\n",
        "test_result = model.predict(x_test)\n",
        "print(test_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwBLbSL7smGT",
        "outputId": "8128652b-14ee-499e-a360-2b2451cc9439"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-3.10385806]] [9.39776831]\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#softmax\n",
        "import torch\n",
        "x_train = torch.FloatTensor([ [1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5],\n",
        " [1,2,5,6], [1,6,6,6], [1,7,7,7] ])\n",
        "y_train = torch.FloatTensor([ [0,0,1], [0,0,1], [0,0,1], [0,1,0], [0,1,0], [0,1,0],\n",
        " [1,0,0], [1,0,0] ])\n",
        "\n",
        "W = torch.randn(4, 3, requires_grad=True)\n",
        "b = torch.randn(1, 3, requires_grad=True)\n",
        "optimizer = torch.optim.Adam([W,b], lr=0.1)\n",
        "\n",
        "for epoch in range(3001):\n",
        "  hypothesis = torch.softmax(torch.mm(x_train, W)+b, dim=1)\n",
        "  cost = -torch.mean(torch.sum(y_train * torch.log(hypothesis), dim=1))\n",
        "  hypothesis = (torch.mm(x_train, W)+b).softmax(dim=1)\n",
        "  cost = -(y_train * torch.log(hypothesis)).sum(dim=1).mean()\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 300 == 0:\n",
        "    print(\"epoch: {}, cost: {:.6f}\".format(epoch, cost.item()))\n",
        "\n",
        "W.requires_grad_(False)\n",
        "b.requires_grad_(False)\n",
        "x_test = torch.FloatTensor([[1,11,10,9], [1,3,4,3], [1,1,0,1]])\n",
        "test_all = torch.softmax(torch.mm(x_test, W)+b, dim=1)\n",
        "print(test_all)\n",
        "print(torch.argmax(test_all, dim=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgQRu2i9tGYu",
        "outputId": "e97c2025-0431-44f4-c32e-7fc9fa9c1a86"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 3.808313\n",
            "epoch: 300, cost: 0.114236\n",
            "epoch: 600, cost: 0.048244\n",
            "epoch: 900, cost: 0.026486\n",
            "epoch: 1200, cost: 0.016680\n",
            "epoch: 1500, cost: 0.011409\n",
            "epoch: 1800, cost: 0.008239\n",
            "epoch: 2100, cost: 0.006178\n",
            "epoch: 2400, cost: 0.004763\n",
            "epoch: 2700, cost: 0.003749\n",
            "epoch: 3000, cost: 0.002998\n",
            "tensor([[1.0000e+00, 1.7465e-18, 4.6994e-37],\n",
            "        [1.8722e-02, 7.8617e-01, 1.9510e-01],\n",
            "        [9.3746e-33, 1.7410e-11, 1.0000e+00]])\n",
            "tensor([0, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#improve softmax\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "x_train = torch.FloatTensor([ [1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5],\n",
        " [1,2,5,6], [1,6,6,6], [1,7,7,7] ])\n",
        "y_train = torch.LongTensor([2,2,2,1,1,1,0,0])\n",
        "\n",
        "model = nn.Linear(4,3)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=1)\n",
        "\n",
        "for epoch in range(3001):\n",
        "  z = model(x_train)\n",
        "  cost = F.cross_entropy(z, y_train)\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 300 == 0:\n",
        "    print(\"epoch: {}, cost: {:.6f}\".format(epoch, cost.item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhB6pZOhtnc5",
        "outputId": "240ff564-9839-41df-f195-83527e87463b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 2.383127\n",
            "epoch: 300, cost: 0.030333\n",
            "epoch: 600, cost: 0.012281\n",
            "epoch: 900, cost: 0.006688\n",
            "epoch: 1200, cost: 0.004211\n",
            "epoch: 1500, cost: 0.002885\n",
            "epoch: 1800, cost: 0.002087\n",
            "epoch: 2100, cost: 0.001568\n",
            "epoch: 2400, cost: 0.001211\n",
            "epoch: 2700, cost: 0.000954\n",
            "epoch: 3000, cost: 0.000764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sklearn softmax\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "x_train = np.array([ [1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5],\n",
        " [1,2,5,6], [1,6,6,6], [1,7,7,7] ])\n",
        "# y에 0, 1, 2 등 둘 이상의 class가 존재 => softmax regression\n",
        "y_train = np.array([ 2, 2, 2, 1, 1, 1, 0, 0 ])\n",
        "logistic = LogisticRegression() # 모델 생성\n",
        "logistic.fit(x_train, y_train) # 학습\n",
        "pred = logistic.predict([[1,11,10,9], [1,3,4,3], [1,1,0,1]]) # test case (값 예측)\n",
        "print(pred) # 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3yC1-ZuwMTQ",
        "outputId": "9136f65f-1f57-41cd-b4ad-636dbe96cfa0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 2 2]\n"
          ]
        }
      ]
    }
  ]
}